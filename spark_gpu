http://www.diva-portal.org/smash/get/diva2:1181003/FULLTEXT01.pdf
p33

■yarn-site.xml(NodeManager)
https://github.com/naver/hadoop/blob/master/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/yarn-default.xml
<property>
  <description>Number of gcores that can be allocated
    for containers. This is used by the RM scheduler when allocating
    resources for containers. This is not used to limit the number of
    gpu cores used by YARN containers.</description>
  <name>yarn.nodemanager.resource.gcores</name>
  <value>0</value>
</property>
<property>
  <description>The minimum allocation for every container request at the RM,
    in terms of GPU cores. Requests lower than this will throw a
    InvalidResourceRequestException.</description>
  <name>yarn.scheduler.minimum-allocation-gcores</name>
  <value>0</value>
</property>
<property>
  <description>The maximum allocation for every container request at the RM,
    in terms of GPU cores. Requests higher than this will throw a
    InvalidResourceRequestException.</description>
  <name>yarn.scheduler.maximum-allocation-gcores</name>
  <value>8</value>
</property>

GPU Support In Spark And GPU/CPU Mixed Resource Scheduling At Production Scale
https://www.slideshare.net/SparkSummit/gpu-support-in-spark-and-gpucpu-mixed-resource-scheduling-at-production-scale-63065895
p10でgpuを利用するstageのDAGが表現されている

SparkのDeep Learning Pipelinesを使ってみた
https://blog.brains-tech.co.jp/entry/2017/10/03/154938

Deep Learning Pipelines — Databricks Documentation
https://docs.databricks.com/applications/deep-learning/deep-learning-pipelines.html

DL4J
https://deeplearning4j.org/

ND4J backends for GPUs and CPUs
https://deeplearning4j.org/docs/latest/deeplearning4j-config-gpu-cpu

Configuring your build tool(SBT)
https://deeplearning4j.org/docs/latest/deeplearning4j-config-buildtools

Deeplearning4J on Spark
https://dev.classmethod.jp/hadoop/hadoop-advent-calendar-20-deeplearning4j/


